{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-08 14:54:04,316] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'conversations': [{'from': 'human',\n",
       "   'value': 'find the office chair that is near the copier'},\n",
       "  {'from': 'gpt',\n",
       "   'value': \"['find', 'the', 'office', 'chair', 'that', 'is', 'near', 'the', 'copier']\"}]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tinyllama_ft.train.finetune import preprocess_llama_2\n",
    "import json\n",
    "data = json.load(open('data/sr3d_84k.json'))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'from': 'human', 'value': 'find the office chair that is near the copier'},\n",
       "  {'from': 'gpt',\n",
       "   'value': \"['find', 'the', 'office', 'chair', 'that', 'is', 'near', 'the', 'copier']\"}]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = [data[0]['conversations']]\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"[INST] <<SYS>>\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n<</SYS>>\\n\\nfind the office chair that is near the copier [/INST] ['find', 'the', 'office', 'chair', 'that', 'is', 'near', 'the', 'copier'] </s>\"]\n",
      "WARNING: tokenization mismatch: 179 vs. 178. (ignored)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,   518, 25580, 29962,  3532, 14816, 29903,  6778,    13,  3492,\n",
       "            526,   263,  8444, 29892,  3390,  1319,   322, 15993, 20255, 29889,\n",
       "          29849,  1234,   408,  1371,  3730,   408,  1950, 29892,  1550,  1641,\n",
       "           9109, 29889, 29871,  3575,  6089,   881,   451,  3160,   738, 10311,\n",
       "           1319, 29892,   443,   621,   936, 29892, 11021,   391, 29892,  7916,\n",
       "            391, 29892,   304, 27375, 29892, 18215, 29892,   470, 27302,  2793,\n",
       "          29889,  3529,  9801,   393,   596, 20890,   526,  5374,   635,   443,\n",
       "           5365,  1463,   322,  6374,   297,  5469, 29889,    13,    13,  3644,\n",
       "            263,  1139,   947,   451,  1207,   738,  4060, 29892,   470,   338,\n",
       "            451,  2114,  1474, 16165,   261,   296, 29892,  5649,  2020,  2012,\n",
       "            310, 22862,  1554,   451,  1959, 29889,   960,   366,  1016, 29915,\n",
       "          29873,  1073,   278,  1234,   304,   263,  1139, 29892,  3113,  1016,\n",
       "          29915, 29873,  6232,  2089,  2472, 29889,    13, 29966,   829, 14816,\n",
       "          29903,  6778,    13,    13,  2886,   278,  8034, 11774,   393,   338,\n",
       "           2978,   278,  5614,   631,   518, 29914, 25580, 29962,  6024,  2886,\n",
       "            742,   525,  1552,   742,   525, 20205,   742,   525,   305,  1466,\n",
       "            742,   525,  5747,   742,   525,   275,   742,   525, 28502,   742,\n",
       "            525,  1552,   742,   525,  9708,   631,  2033, 29871,     2]]),\n",
       " 'labels': tensor([[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "            'TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
    "            model_max_length=2048,\n",
    "            padding_side=\"right\",\n",
    "            use_fast=False,\n",
    "        )\n",
    "preprocess_llama_2(source, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyllama_ft.conversation import conv_llama_2\n",
    "conv = conv_llama_2.copy()\n",
    "roles = conv_llama_2.roles\n",
    "inp = 'find the office chair that is near the copier'\n",
    "conv.append_message(conv_llama_2.roles[0], inp)\n",
    "conv.append_message(conv_llama_2.roles[1], None)\n",
    "prompt = conv.get_prompt()\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('USER', 'ASSISTANT')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'find the office chair that is near the copier'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = 'find the office chair that is near the copier'\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[INST] <<SYS>>\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n<</SYS>>\\n\\nUSER [/INST]<s>[INST] find the office chair that is near the copier [/INST]\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langsplat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
